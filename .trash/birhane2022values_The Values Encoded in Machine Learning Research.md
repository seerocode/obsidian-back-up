# The Values Encoded in Machine Learning Research

``` ad-info
title: Metadata
- **CiteKey**: {{citekey}}
- **Type**: ConferencePaper
- **Author**: Birhane, Abeba; Kalluri, Pratyusha; Card, Dallas; Agnew, William; Dotan, Ravit; Bao, Michelle
- **Editor**: {{editor}}
- **Translator**: {{translator}}
- **Publisher**: Association for Computing Machinery
- **Location**: New York, NY, USA
- **Series**: FAccT '22
- **Series Number**: {{seriesNumber}}
- **Journal**: 2022 ACM Conference on Fairness, Accountability, and Transparency
- **Volume**: {{volume}}
- **Issue**: {{issue}}
- **Pages**: 173â€“184
- **Year**: 2022 
- **DOI**: 10.1145/3531146.3533083
- **ISSN**: {{ISSN}}
- **ISBN**: 978-1-4503-9352-2
```
```ad-quote
title: Abstract
Machine learning currently exerts an outsized influence on the world, increasingly affecting institutional practices and impacted communities. It is therefore critical that we question vague conceptions of the field as value-neutral or universally beneficial, and investigate what specific values the field is advancing. In this paper, we first introduce a method and annotation scheme for studying the values encoded in documents such as research papers. Applying the scheme, we analyze 100 highly cited machine learning papers published at premier machine learning conferences, ICML and NeurIPS. We annotate key features of papers which reveal their values: their justification for their choice of project, which attributes of their project they uplift, their consideration of potential negative consequences, and their institutional affiliations and funding sources. We find that few of the papers justify how their project connects to a societal need (15%) and far fewer discuss negative potential (1%). Through line-by-line content analysis, we identify 59 values that are uplifted in ML research, and, of these, we find that the papers most frequently justify and assess themselves based on Performance, Generalization, Quantitative evidence, Efficiency, Building on past work, and Novelty. We present extensive textual evidence and identify key themes in the definitions and operationalization of these values. Notably, we find systematic textual evidence that these top values are being defined and applied with assumptions and implications generally supporting the centralization of power. Finally, we find increasingly close ties between these highly cited papers and tech companies and elite universities.
```
```ad-abstract
title: Files and Links
- **Url**: https://doi.org/10.1145/3531146.3533083
- **Uri**: http://zotero.org/users/10910988/items/WDHC7QEW
- **Eprint**: {{eprint}}
- **File**: [birhane2022values_The Values Encoded in Machine Learning Research.pdf](file:////Users/ro/Library/CloudStorage/GoogleDrive-rone@seas.upenn.edu/My%20Drive/Zotero/birhane2022values_The%20Values%20Encoded%20in%20Machine%20Learning%20Research.pdf); [Notion](file:///)
- **Local Library**: [Zotero](zotero://select/library/items/WDHC7QEW)
```
```ad-note
title: Tags and Collections
- **Keywords**: Corporate ties; Encoded values of ML; ICML; NeurIPS; Power asymmetries; algorithmic justice; notion
- **Collections**: To Read
```

----

## Comments



----

## Extracted Annotations
